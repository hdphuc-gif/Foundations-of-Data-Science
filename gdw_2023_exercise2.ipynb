{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57411724",
   "metadata": {},
   "source": [
    "# Foundations of Data Science (GDW) 2023\n",
    "\n",
    "\n",
    "\n",
    "# Exercise II: Parallel Computing\n",
    "\n",
    "Parallel processing is an important paradigm for scaling computation intensive calculations. In this exercise you will practice two paradigms in python:\n",
    "- MapReduce\n",
    "- Job pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61865c50",
   "metadata": {},
   "source": [
    "## Part 1: MapReduce\n",
    "\n",
    "Let us start with an example:\n",
    "\n",
    "Suppose you have a kitchen to run and access to several ingredients for making a cheese burger:\n",
    "\n",
    "- Lettuce\n",
    "- Onions\n",
    "- Pickles\n",
    "- Tomatos\n",
    "- Cheese\n",
    "- Patty\n",
    "- Buns\n",
    "- Bottles of sauce\n",
    "\n",
    "### Task 1.1\n",
    "Assuming you can apply as many workers as ingredients, design a MapReduce task to parallelize making a Burger and describe the steps below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f0ce16",
   "metadata": {},
   "source": [
    " --->\n",
    " \n",
    " --->\n",
    " \n",
    " --->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37e5b75",
   "metadata": {},
   "source": [
    "### Prerequisites\n",
    "\n",
    "Now, we will take a look at another example, this time with code.\n",
    "\n",
    "Before running this example, you might need to install the python package `mrjob`, e.g. by calling\n",
    "\n",
    "`pip install mrjob`\n",
    "\n",
    "*Note: You do not need a hadoop installation for this exercise, as we are using the simulated local mode.*\n",
    "\n",
    "Running `mrjob` from jupyterlab is a bit tricky as you will ﬁnd out in the following: We structure the job description and job execution into diﬀerent cells. In the ﬁrst cell we use the ﬁrst line to store its contents in a python ﬁle (using the magic `%%file <filename>` notation), in the next cells we can import this module (line 1). \n",
    "\n",
    "Since jupyterlab caches the loaded packages, after execution of the second cell changes\n",
    "to the ﬁrst would not be loaded again. Therefore, we utilize the package reload (lines 2 and 3, in the\n",
    "second cell) to force a reload of the module exported by the ﬁrst cell.\n",
    "    \n",
    "In the following yu will see how to count characters and lines in a text ﬁle using map reduce (and you\n",
    "will add word count afterwards by yourselves).\n",
    "\n",
    "You can choose your own text file or download the provided ﬁle `big.txt` from moodle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0675d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file mrcharcount.py\n",
    "\n",
    "from mrjob.job import MRJob\n",
    "\n",
    "class MRWordCount(MRJob):\n",
    "    def mapper(self, _, line):\n",
    "        yield \"chars\", len(line)\n",
    "        yield \"lines\", 1\n",
    "                 \n",
    "    def reducer(self, key, values):\n",
    "        s = sum(values)\n",
    "        yield key, s\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    MRWordCount.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d3da1c",
   "metadata": {},
   "source": [
    "After executing the previous cell, you will notice that a .py file appeared in your notebook folder. You are now able to import it and use any functions that are provided by the newly created module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81916cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mrcharcount\n",
    "from importlib import reload \n",
    "reload(mrcharcount)\n",
    "\n",
    "file = 'big.txt'\n",
    "mr_job = mrcharcount.MRWordCount(args=[file])\n",
    "print(f\"Counting occurences in {file}...\")\n",
    "with mr_job.make_runner() as runner:\n",
    "    runner.run()\n",
    "    for line in mr_job.parse_output(runner.cat_output()):\n",
    "        print(f\"{line[0]}: {line[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3fe33a",
   "metadata": {},
   "source": [
    "The warning about the lack of config specifications can be ignored here, as mrjob will just use auto-config."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7760445b",
   "metadata": {},
   "source": [
    "### Task 1.2\n",
    "Modify the listing above such that it also returns the number of words. \n",
    "\n",
    "Hint: You may separate a string `s` into its words by application of the function `s.split()`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4497e62a",
   "metadata": {},
   "source": [
    "## Part 2: Job Pooling\n",
    "Another often used method to perform jobs in parallel are worker pools, which are separate processes spawned from your main process. The results need to be collected by the coordinator, thus, there needs to be some synchronization to wait for jobs to finish.\n",
    "\n",
    "In the following you see how to spawn a child process (on your machine) with the `multiprocessing` python package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f080b232",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file joblist.py\n",
    "\n",
    "from multiprocessing import Process\n",
    "import os\n",
    "\n",
    "def info(title):\n",
    "    # provides information on current system process \n",
    "    print(title)\n",
    "    print('module name:', __name__)\n",
    "    print('parent process id:', os.getppid())\n",
    "    print('own process id:', os.getpid())\n",
    "\n",
    "def f(name):\n",
    "    info('Information on function f')\n",
    "    print('hello', name)\n",
    "    print()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    info('Information on function main')\n",
    "    p = Process(target=f, args=('bob',))\n",
    "    p.start()\n",
    "    p.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74dd61d",
   "metadata": {},
   "source": [
    "You can run the .py file directly from your notebook with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6629a0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i 'joblist.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b831e440",
   "metadata": {},
   "source": [
    "We want to calculate a lot of squares now, with help of the `multiprocessing` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a25e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file workerpool_simple.py\n",
    "\n",
    "from multiprocessing import Pool, TimeoutError\n",
    "import time\n",
    "import os\n",
    "\n",
    "def f(x):\n",
    "    # Compute square of input value\n",
    "    return x*x\n",
    "\n",
    "mem_size = 1400000000\n",
    "a=range(mem_size)\n",
    "\n",
    "num_cpu=os.cpu_count()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(f\"Number of CPU cores: {num_cpu}\")\n",
    "    # start a worker process for each of your cpu cores\n",
    "    with Pool(processes=num_cpu) as pool:\n",
    "\n",
    "        # Distribute evaluation of a function to workers  \n",
    "        result=pool.map(f, a)\n",
    "        \n",
    "        # Display results\n",
    "        print(f\"All squares: \\n {result}\") # outputs a looooong list of square numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20e3077",
   "metadata": {},
   "source": [
    "*Note:* you might have to adjust the `mem_size` parameter if you get errors like MemoryErrors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838cefed",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i 'workerpool_simple.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e751ef",
   "metadata": {},
   "source": [
    "## Task 2.1\n",
    "Given the script above, that computes square numbers in parallel, apply some modifications, such that it counts the workload of each individal process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d0bcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23029f06",
   "metadata": {},
   "source": [
    "Test your file in the same way like the example above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b745d7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
