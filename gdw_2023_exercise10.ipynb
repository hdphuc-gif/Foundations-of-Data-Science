{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Foundations of Data Science (GDW) 2023\n",
    "\n",
    "\n",
    "\n",
    "# Exercise X: Classification Quality & SVMs\n",
    "\n",
    "This week, we will take a look at precision and recall as quality measures for classification models, and additionally at the Support Vector Machine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Precision and Recall\n",
    "\n",
    "For binary classification problems the known quality measures MSE etc. may hardly be applied.\n",
    "Instead, performance is often measured in terms of Precision and Recall. These measures are\n",
    "defined by the following ratios\n",
    "\n",
    "$Precision =\\frac{TP}{TP + FP}$\n",
    "\n",
    "and\n",
    "\n",
    "$Recall = \\frac{TP}{TP + FN}$\n",
    "\n",
    "where $TP$ are the number of true positives, $FP$ is the number of false positives, $FN$ is the number of\n",
    "false negatives.\n",
    "\n",
    "Suppose a binary classification problem, spam classification, suppose further, we projected the features to the interval $x \\in (0, 1)$ and have a decision function f(x) dependant on this feature.\n",
    "\n",
    "$f(x) = \\quad \\text{\"spam\" if } x \\geq 0, \\\\\\quad\\quad\\quad\\quad \\text{\"no spam\" if } x < 0$.\n",
    "\n",
    "In the next figures, you can see the classification results of different models. The binary label $y$ is indicated by the color below the data\n",
    "points, from which you can see whether these points are $TP$ , $TF$ , $FN$ or $FP$ according to the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For generating the images we want, we need to install the `Pillow` library first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install Pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afterwards, we can execute the script below, which generates images for classification results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from IPython.display import display\n",
    "\n",
    "class_results = [[\"TN\", \"TN\",\"TN\",\"TN\",\"TN\",\"TN\",\"TN\",\"TN\",\"TN\", \"TN\",\"TN\",\"TN\",\"TN\",\"TN\",\"TN\", \"FN\", \n",
    "                 \"TN\", \"FN\", \"TN\", \"FN\", \"FP\", \"TP\", \"FP\", \"TP\", \"TP\", \"TP\", \"TP\", \"TP\", \"TP\", \"TP\"],\n",
    "                [\"TN\", \"TN\",\"TN\",\"TN\",\"TN\",\"TN\",\"TN\",\"TN\",\"TN\", \"TN\",\"TN\",\"TN\",\"TN\",\"TN\",\"TN\", \"FN\", \n",
    "                 \"TN\", \"FN\", \"TN\", \"FN\", \"TN\", \"FN\", \"FP\", \"TP\", \"TP\", \"TP\", \"TP\", \"TP\", \"TP\", \"TP\"],\n",
    "                 [\"TN\", \"TN\",\"TN\",\"TN\",\"TN\",\"TN\",\"TN\",\"TN\",\"TN\", \"TN\",\"TN\",\"TN\",\"TN\",\"TN\",\"TN\", \"FN\", \n",
    "                 \"TN\", \"FN\", \"FP\", \"TP\", \"FP\", \"TP\", \"FP\", \"TP\", \"TP\", \"TP\", \"TP\", \"TP\", \"TP\", \"TP\"]]\n",
    "class_thresholds = [20, 22, 18]  \n",
    "\n",
    "def generate_class_colors(results):\n",
    "    circle_colors = [\"red\", \"red\", \"green\", \"green\"]\n",
    "    labels = [\"TN\", \"FP\", \"TP\", \"FN\"]\n",
    "    result_colors = []\n",
    "    for res in results:\n",
    "        result_colors.append(circle_colors[labels.index(res)])\n",
    "    \n",
    "    return result_colors\n",
    "\n",
    "def generate_image(circle_colors, labels, threshold, image_width=850, circle_radius=14, label_font_size=14):\n",
    "    image_height = circle_radius*2 + label_font_size + 30\n",
    "    image = Image.new(\"RGB\", (image_width, image_height), \"white\")\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    font = ImageFont.truetype(\"Pillow/Tests/fonts/FreeMono.ttf\")\n",
    "    \n",
    "    start_x = (image_width - len(circle_colors) * (circle_radius*2)) - 10\n",
    "    \n",
    "    for i, (color, label) in enumerate(zip(circle_colors, labels)):\n",
    "            \n",
    "        draw.ellipse(\n",
    "            [(start_x, 10), (start_x + circle_radius*2, circle_radius*2 + 10)],\n",
    "            fill=color,\n",
    "            outline=\"black\",\n",
    "        )\n",
    "        \n",
    "        label_width, label_height = draw.textsize(label)\n",
    "        label_position = (start_x + circle_radius - label_width // 2, circle_radius*2 + 20,)\n",
    "        draw.text(label_position, label, fill=\"black\", font=font)\n",
    "        \n",
    "        if i == threshold-1:\n",
    "            line_margin = 3\n",
    "            line_x = start_x + circle_radius*2 + line_margin\n",
    "            line_y_start = 0\n",
    "            line_y_end = circle_radius*2 + 35\n",
    "            draw.line([(line_x, line_y_start), (line_x, line_y_end)], fill=\"black\")\n",
    "            start_x += line_margin*2\n",
    "        \n",
    "        start_x += circle_radius*2\n",
    "        \n",
    "    display(image)\n",
    "\n",
    "for i, (class_result, class_threshold) in enumerate(zip(class_results, class_thresholds)):\n",
    "    result_colors = generate_class_colors(class_result)\n",
    "    print(f\"Classification model {i+1}:\")\n",
    "    generate_image(result_colors, class_result, threshold=class_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.1\n",
    "Compute precision and recall for each of these classifiers. The vertical lines denote the classification thresholds (leftmost = 0, rightmost = 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*write your answers here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: The Support Vector Machine\n",
    "Before we focus on the support vector method, it is important to understand classification with a linear\n",
    "model. Next, we exemplify this for the well-known iris datset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import datasets , svm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "normal_plane =[0, -1, 2]\n",
    "\n",
    "#sign function returns -1 for negative x and 1 for positive x, 0 for edge cases\n",
    "def sgn(x):\n",
    "    return 1 if x > 0 else -1 if x < 0 else 0\n",
    "\n",
    "def distance (x, normalvector) :\n",
    "    return (np.dot(x, normalvector[1:]) + normalvector[0])\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, [0 ,1]] # features\n",
    "y = iris.target # labels\n",
    "y = (y==0)*2 - 1\n",
    "\n",
    "y_pred = [0]*y.size\n",
    "i = 0\n",
    "\n",
    "for x in X:\n",
    "    y_pred[i]= sgn(distance(x, normal_plane))\n",
    "    i += 1\n",
    "    \n",
    "# plt . scatter ( X [: ,0] , X [: ,1] , c = y )\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y_pred)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    " # fit the model\n",
    "for kernel in ('linear', 'rbf', 'poly'):\n",
    "    clf = svm.SVC(kernel=kernel, gamma=10)\n",
    "    clf.fit(X_train, y_train)\n",
    "    plt.figure()\n",
    "    plt.clf()\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, zorder=10, cmap=plt.cm.Paired, edgecolor='k', s=20)\n",
    "\n",
    "    # Circle out the test data\n",
    "    plt.scatter(X_test[:, 0], X_test[:, 1], s=80, facecolors='none', zorder=10, edgecolor='k')\n",
    "\n",
    "    plt.axis('tight')\n",
    "    x_min = X[:, 0].min()\n",
    "    x_max = X[:, 0].max()\n",
    "    y_min = X[:, 1].min()\n",
    "    y_max = X[:, 1].max()\n",
    "\n",
    "    XX, YY = np.mgrid[x_min:x_max:200j, y_min:y_max:200j]\n",
    "    Z = clf.decision_function(np.c_[XX.ravel(), YY.ravel()])\n",
    "\n",
    "    # Put the result into a color plot\n",
    "    Z = Z.reshape(XX.shape)\n",
    "    # plt . pcolormesh ( XX , YY , Z > 0 , cmap = plt . cm . Paired )\n",
    "    plt.contour(XX, YY, Z, colors=['k', 'k', 'k'], linestyles=['--','-','--'], levels=[-.5, 0, .5])\n",
    "    plt.title(kernel)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.1\n",
    "For the code above, apply the following changes:\n",
    "\n",
    "`X = iris.data[:, [0,3]] #features` and\n",
    "`y = (y==0)*2 - 1 #labels`\n",
    "\n",
    "What is the best SVM for this data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*write your answer here*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
